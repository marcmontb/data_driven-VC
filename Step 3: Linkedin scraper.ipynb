{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650cd0b-5866-453c-9f35-a6584b510e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code shown in this section is the code used to scrape LinkedIn profiles. The code used to scrape\n",
    "#the profiles in the database returns the scraped information from the profiles (name, description,\n",
    "#location, experience, education and URL, without the data points containing dates and locations in the\n",
    "#scraping of the experience and education sections). \n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from parsel import Selector\n",
    "import pandas as pd\n",
    "\n",
    "# read the profiles, save the data\n",
    "writer = csv.writer(open('database.csv', 'w'))\n",
    "writer.writerow(['name', 'description', 'location', 'experience', 'education', 'ln_url'])\n",
    "\n",
    "driver = webdriver.Chrome('/Users/Gonzalo Rodríguez/chromedriver')\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "sleep(1)\n",
    "\n",
    "# Put your LinkedIn email here\n",
    "username_input = driver.find_element(\"name\", 'session_key')\n",
    "username_input.send_keys('grodriguez@inveready.com')\n",
    "\n",
    "# Put your LinkedIn password here\n",
    "password_input = driver.find_element(\"name\", 'session_password')\n",
    "password_input.send_keys('password')\n",
    "sleep(2)\n",
    "\n",
    "# Click on the sign in button\n",
    "driver.find_element(\"xpath\", '//button[text()=\"Iniciar sesión\"]').click()\n",
    "sleep(2)\n",
    "\n",
    "# List LinkedIn profiles\n",
    "lst = []\n",
    "for profile in profile_urls:\n",
    "    driver.get(profile)\n",
    "    sleep(2)\n",
    "\n",
    "    try:\n",
    "        soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        dom = etree.HTML(str(soup2))\n",
    "        sel = Selector(text=driver.page_source)\n",
    "\n",
    "        # Get name\n",
    "        try:\n",
    "            target_name = soup2.find(\"h1\", {\"class\": \"text-heading-xlarge inline t-24 v-align-middle break-words\"})\n",
    "            name = target_name.get_text().strip()\n",
    "        except:\n",
    "            name = ''\n",
    "\n",
    "        # Get description\n",
    "        try:\n",
    "            target_title = soup2.find(\"div\", {\"class\": \"text-body-medium break-words\"})\n",
    "            title = target_title.get_text().strip()\n",
    "        except:\n",
    "            title = ''\n",
    "\n",
    "        # Get location\n",
    "        try:\n",
    "            tree = etree.ElementTree(dom)\n",
    "            find_text = etree.XPath(\"//div[@class='application-outlet']\")\n",
    "            for target in find_text(dom):\n",
    "                loc = tree.getpath(target)\n",
    "                location_xpath = loc + '/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[2]/span[1]/text()'\n",
    "                location = dom.xpath(location_xpath)[0].strip()\n",
    "        except:\n",
    "            location = ''\n",
    "        location = location.strip()\n",
    "        ln_url = profile\n",
    "\n",
    "    # Get Experience\n",
    "    # Find section\n",
    "    tree = etree.ElementTree(dom)\n",
    "    find_text = etree.XPath(\"//div[@id='experience']\")\n",
    "    for target in find_text(dom):\n",
    "        pos_exp = tree.getpath(target)\n",
    "        list1 = [i for i in pos_exp]\n",
    "        list1[-2] = str(int(pos_exp[-2]) + 2)\n",
    "        if 'navigation-index-see-all-experiences' in str(soup2):\n",
    "            list1.append('/div/div/div/a')\n",
    "            pos_exp = ''.join(list1)\n",
    "            # Go to see all experiences, count experiences\n",
    "            driver.find_element(\"xpath\", pos_exp).click()\n",
    "            sleep(2)\n",
    "            soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            dom = etree.HTML(str(soup2))\n",
    "            sel = Selector(text=driver.page_source)\n",
    "            sel_exp = str(soup2)\n",
    "            num_exp = sel_exp.count('<li class=\"pvs-list__paged-list-item artdeco-list__item \\\n",
    "                                    pvs-list__item--line-separated pvs-list__item--one-column\"')\n",
    "            i = 0\n",
    "            experiences = []\n",
    "            while i < num_exp:\n",
    "                # Identify if it is a position with promotions (reads differently)\n",
    "                i = i + 1\n",
    "                tree = etree.ElementTree(dom)\n",
    "                find_text = etree.XPath(\"//div[@class='application-outlet']\")\n",
    "                for target in find_text(dom):\n",
    "                    pos_exp = tree.getpath(target)\n",
    "                    listi1 = pos_exp + '/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul' + '/li[' + str(i) + ']'\n",
    "                    sel_li = ''\n",
    "                    try:\n",
    "                        sel_li = sel.xpath(listi1).extract()[0]\n",
    "                    except:\n",
    "                        sel_li = ''\n",
    "                    if sel_li.count('li class=\"pvs-list__paged-list-item pvs-list__item--onecolumn\"') > 1: # Has promotions\n",
    "                        # Get info\n",
    "                        listi1 = listi1 + '/div/div/div[2]'\n",
    "                        company = listi1 + '/div[1]/a/div/div/div/div/span[1]/text()'\n",
    "                        try:\n",
    "                            company1 = dom.xpath(company)[0]\n",
    "                        except:\n",
    "                            company1 = ''\n",
    "                        company1 = company1.strip()\n",
    "                        position = listi1 + '/div[2]/ul/li/div/div/div[1]/ul/li[1]/div/div/div[2]/div[1]/a/div/div/div/div/span[1]/text()'\n",
    "                        try:\n",
    "                            position1 = dom.xpath(position)[0]\n",
    "                        except:\n",
    "                            position1 = ''\n",
    "                        position1 = position1.strip()\n",
    "                        \n",
    "                        if sel_li.count('li class=\"pvs-list__paged-list-item pvs-list__item--onecolumn\"') > 1:  # has promotions\n",
    "                            # More code for promotions\n",
    "                            # ...\n",
    "                        else:  # has no promotions\n",
    "                            listi1 = listi1 + '/div/div/div[2]/div/div[1]'\n",
    "                            position = listi1 + '/div/div/div/div/span[1]/text()'\n",
    "                            try:\n",
    "                                position1 = dom.xpath(position)[0]\n",
    "                            except:\n",
    "                                position1 = ''\n",
    "                            position1 = position1.strip()\n",
    "                            company = listi1 + '/span[1]/span[1]/text()'\n",
    "                            try:\n",
    "                                company1 = dom.xpath(company)[0]\n",
    "                            except:\n",
    "                                company1 = ''\n",
    "                            company1 = company1.strip()\n",
    "                        experiences.extend([position1, company1])\n",
    "                        \n",
    "                        # Go back if you are inside all experiences\n",
    "                        driver.execute_script(\"window.history.go(-1)\")\n",
    "                        sleep(2)\n",
    "                        soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                        dom = etree.HTML(str(soup2))\n",
    "                        sel = Selector(text=driver.page_source)\n",
    "                    \n",
    "                    else:\n",
    "                        list1.append('/ul')\n",
    "                        pos_exp = ''.join(list1)\n",
    "                        sel_exp = sel.xpath(pos_exp).extract()[0]\n",
    "                        # Find jobs (count experiences, add remaining xpath 'manually')\n",
    "                        num_exp = sel_exp.count('<li class=\"artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\"')\n",
    "                        i = 0\n",
    "                        experiences = []\n",
    "                        while i < num_exp:\n",
    "                            i = i + 1\n",
    "                        # Identify if it is a position with promotions (reads differently)\n",
    "                            listi1 = list1.copy()\n",
    "                            listi1.append('/li[' + str(i) + ']')\n",
    "                            pos_li = ''.join(listi1)\n",
    "                            try:\n",
    "                                sel_li = sel.xpath(pos_li).extract()[0]\n",
    "                            except:\n",
    "                                sel_li = ''\n",
    "                            \n",
    "                            if 'pvs-entity--with-path' in sel_li:  # has promotions\n",
    "                                listi1.append('/div/div[2]')\n",
    "                                company = listi1.copy()\n",
    "                                company.append('/div[1]/a/div/div/div/div/span[1]/text()')\n",
    "                                company = ''.join(company)\n",
    "                                try:\n",
    "                                    company1 = dom.xpath(company)[0]\n",
    "                                except:\n",
    "                                    company1 = ''\n",
    "                                company1 = company1.strip()\n",
    "                            \n",
    "                                position = listi1.copy()\n",
    "                                position.append('/div[2]/ul/li[1]/div/div[2]/div/a/div/div/div/div/span[1]/text()')\n",
    "                                position = ''.join(position)\n",
    "                                try:\n",
    "                                    position1 = dom.xpath(position)[0]\n",
    "                                except:\n",
    "                                    position1 = ''\n",
    "                                position1 = position1.strip()\n",
    "                            else:  # has no promotions\n",
    "                                listi1.append('/div/div[2]/div/div[1]')\n",
    "                                position = listi1.copy()\n",
    "                                position.append('/div/div/div/div/span[1]/text()')\n",
    "                                position = ''.join(position)\n",
    "                                try:\n",
    "                                    position1 = dom.xpath(position)[0]\n",
    "                                except:\n",
    "                                    position1 = ''\n",
    "                                position1 = position1.strip()\n",
    "                                company = listi1.copy()\n",
    "                                company.append('/span[1]/span[1]/text()')\n",
    "                                company = ''.join(company)\n",
    "                                try:\n",
    "                                    company1 = dom.xpath(company)[0]\n",
    "                                except:\n",
    "                                    company1 = ''\n",
    "                                company1 = company1.strip()\n",
    "                                experiences.extend([position1, company1])\n",
    "                            \n",
    "                        # Get education\n",
    "                        tree = etree.ElementTree(dom)\n",
    "                        find_text = etree.XPath(\"//div[@id='education']\")\n",
    "                        for target in find_text(dom):\n",
    "                            pos_edu = tree.getpath(target)\n",
    "                            list2 = [i for i in pos_edu]\n",
    "                            list2[-2] = str(int(pos_edu[-2]) + 2)\n",
    "                            if 'navigation-index-see-all-education' in str(soup2):\n",
    "                                list2.append('/div/div/div/a')\n",
    "                                pos_edu = ''.join(list2)\n",
    "                                # Go to see all education\n",
    "                                driver.find_element(\"xpath\", pos_edu).click()\n",
    "                                sleep(2)\n",
    "                                soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                                dom = etree.HTML(str(soup2))\n",
    "                                sel = Selector(text=driver.page_source)\n",
    "                                sel_edu = str(soup2)\n",
    "                                num_edu = sel_edu.count('<li class=\"pvs-list__paged-list-item artdeco-list__item \\\n",
    "                                                       pvs-list__item--line-separated pvs-list__item--one-column\"')\n",
    "                                i = 0\n",
    "                                education = []\n",
    "                                while i < num_edu:\n",
    "                                    i = i + 1\n",
    "                                    tree = etree.ElementTree(dom)\n",
    "                                    find_text = etree.XPath(\"//div[@class='application-outlet']\")\n",
    "                                    for target in find_text(dom):\n",
    "                                        pos_exp = tree.getpath(target)\n",
    "                                        listi2 = pos_exp + '/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul' + '/li[' + str(i) + ']/div/div/div[2]/div[1]/a'\n",
    "                                        school = listi2 + '/div/div/div/div/span[1]/text()'\n",
    "                                        try:\n",
    "                                            school1 = dom.xpath(school)[0]\n",
    "                                        except:\n",
    "                                            school1 = ''\n",
    "                                        school1 = school1.strip()\n",
    "                                        degree = listi2 + '/span[1]/span[1]/text()'\n",
    "                                        try:\n",
    "                                            degree1 = dom.xpath(degree)[0]\n",
    "                                        except:\n",
    "                                            degree1 = ''\n",
    "                                        degree1 = degree1.strip()\n",
    "                                        education.extend([school1, degree1])\n",
    "                            else:\n",
    "                                list2.append('/ul')\n",
    "                                pos_edu = ''.join(list2)\n",
    "                                sel_edu = sel.xpath(pos_edu).extract()[0]\n",
    "                                num_edu = sel_edu.count('<li class=\"artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column\"')\n",
    "                                i = 0\n",
    "                                education = []\n",
    "                                while i < num_edu:\n",
    "                                    i = i + 1\n",
    "                                    listi2 = list2.copy()\n",
    "                                    listi2.append('/li[' + str(i) + ']/div/div[2]/div/a')\n",
    "                                    school = listi2.copy()\n",
    "                                    school.append('/div/div/div/div/span[1]/text()')\n",
    "                                    school = ''.join(school)\n",
    "                                    try:\n",
    "                                        school1 = dom.xpath(school)[0]\n",
    "                                    except:\n",
    "                                        school1 = ''\n",
    "                                    school1 = school1.strip()\n",
    "                                    degree = listi2.copy()\n",
    "                                    degree.append('/span[1]/span[1]/text()')\n",
    "                                    degree = ''.join(degree)\n",
    "                                    try:\n",
    "                                        degree1 = dom.xpath(degree)[0]\n",
    "                                    except:\n",
    "                                        degree1 = ''\n",
    "                                    degree1 = degree1.strip()\n",
    "                                    education.extend([school1, degree1])\n",
    "                        \n",
    "                            writer.writerow([name, title, location, experiences, education, ln_url])\n",
    "                            lst.append([name, title, location, experiences, education, ln_url])\n",
    "                        \n",
    "                        except Exception as e:\n",
    "                            print(\"Error occurred:\", e)\n",
    "                            continue\n",
    "                        \n",
    "                print(lst)\n",
    "                driver.quit()\n",
    "                                                      \n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
