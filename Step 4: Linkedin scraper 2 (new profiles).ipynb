{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638b4d8-f59a-4936-a814-dad4544e9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code used to scrape new profiles (shown below) looks for profile URLs using Google Search and\n",
    "#the keywords specified by the user and returns the scraped information from the profiles (name,\n",
    "#description, location, experience, education and URL, including the data points containing dates and\n",
    "#locations in the scraping of the experience and education sections).\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from parsel import Selector\n",
    "from flask import request, render_template\n",
    "\n",
    "def new_profiles():\n",
    "    experiences = request.form['experiences']\n",
    "    location = request.form['location']\n",
    "    studies = request.form['studies']\n",
    "\n",
    "    # Preparing csv file to store result later\n",
    "    writer = csv.writer(open('testing.csv', 'w'))\n",
    "    writer.writerow(['name', 'description', 'location', 'experience', 'education', 'ln_url'])\n",
    "\n",
    "    driver = webdriver.Chrome('/Users/Gonzalo Rodríguez/chromedriver')\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "    sleep(1)\n",
    "\n",
    "    # Put your LinkedIn email here\n",
    "    username_input = driver.find_element(\"name\", 'session_key')\n",
    "    username_input.send_keys('grodriguez@inveready.com')\n",
    "\n",
    "    # Put your LinkedIn password here\n",
    "    password_input = driver.find_element(\"name\", 'session_password')\n",
    "    password_input.send_keys('password')\n",
    "    sleep(2)\n",
    "\n",
    "    # Click on the sign in button\n",
    "    driver.find_element(\"xpath\", '//button[text()=\"Iniciar sesión\"]').click()\n",
    "    sleep(2)\n",
    "\n",
    "    profile_urls = []  # To store the Profile URLs\n",
    "    text = 'site:linkedin.com/in/ AND \"{}\" AND \"{}\" AND \"{}\"'.format(experiences, location, studies)\n",
    "    query = 'https://google.com/search?q=' + text\n",
    "    cookies = {\"CONSENT\": \"YES+shp.gws-20210330-0-RC1.de+FX+412\"}\n",
    "    response = requests.get(query, cookies=cookies)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for anchor in soup.find_all('a'):\n",
    "        url = anchor[\"href\"]\n",
    "        if 'https://es.linkedin.com/' in url:\n",
    "            url = url[7:url.find('&')]\n",
    "            profile_urls.append(url)\n",
    "\n",
    "    # Visit each profile on LinkedIn and grab details we want to get\n",
    "    lst = []\n",
    "    profile_urls1 = ['https://es.linkedin.com/in/julienpalier', 'https://es.linkedin.com/in/eduardgarciaf/en']\n",
    "    for profile in profile_urls1:\n",
    "        driver.get(profile)\n",
    "        sleep(2)\n",
    "        try:\n",
    "            soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            dom = etree.HTML(str(soup2))\n",
    "            sel = Selector(text=driver.page_source)\n",
    "\n",
    "            # Get name (can get also with xpath)\n",
    "            try:\n",
    "                target_name = soup2.find(\"h1\", {\"class\": \"text-heading-xlarge inline t-24 v-align-middle break-words\"})\n",
    "                name = target_name.get_text().strip()\n",
    "            except:\n",
    "                name = ''\n",
    "\n",
    "            # Get Description (can get also with xpath)\n",
    "            try:\n",
    "                target_title = soup2.find(\"div\", {\"class\": \"text-body-medium break-words\"})\n",
    "                title = target_title.get_text().strip()\n",
    "            except:\n",
    "                title = ''\n",
    "\n",
    "            # Get location (can get also without xpath)\n",
    "            try:\n",
    "                tree = etree.ElementTree(dom)\n",
    "                find_text = etree.XPath(\"//div[@class='application-outlet']\")\n",
    "                for target in find_text(dom):\n",
    "                    loc = tree.getpath(target)\n",
    "                    location_xpath = loc + '/div[3]/div/div/div[2]/div/div/main/section[1]/div[2]/div[2]/div[2]/span[1]/text()'\n",
    "                    location = dom.xpath(location_xpath)[0]\n",
    "            except:\n",
    "                location = ''\n",
    "            location = location.strip()\n",
    "            ln_url = profile\n",
    "\n",
    "            # Get Experience\n",
    "            tree = etree.ElementTree(dom)\n",
    "            find_text = etree.XPath(\"//div[@id='experience']\")\n",
    "            for target in find_text(dom):\n",
    "                pos_exp = tree.getpath(target)\n",
    "                list1 = [i for i in pos_exp]\n",
    "                list1[-2] = str(int(pos_exp[-2]) + 2)\n",
    "                if 'navigation-index-see-all-experiences' in str(soup2):\n",
    "                    list1.append('/div/div/div/a')\n",
    "                    pos_exp = ''.join(list1)\n",
    "                    driver.find_element(\"xpath\", pos_exp).click()\n",
    "                    sleep(2)\n",
    "                    soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    dom = etree.HTML(str(soup2))\n",
    "                    sel = Selector(text=driver.page_source)\n",
    "                    sel_exp = str(soup2)\n",
    "                    num_exp = sel_exp.count('<li class=\"pvs-list__paged-list-item artdeco-list__item \\\n",
    "                                            pvs-list__item--line-separated pvs-list__item--one-column\"')\n",
    "                    i = 0\n",
    "                    experiences = []\n",
    "                    while i < num_exp:\n",
    "                        i += 1\n",
    "                        tree = etree.ElementTree(dom)\n",
    "                        find_text = etree.XPath(\"//div[@class='application-outlet']\")\n",
    "                        for target in find_text(dom):\n",
    "                            pos_exp = tree.getpath(target)\n",
    "                            listi1 = pos_exp + '/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[' + str(i) + ']'\n",
    "                            try:\n",
    "                                sel_li = sel.xpath(listi1).extract()[0]\n",
    "                                if sel_li.count('li class=\"pvs-list__paged-list-item pvs-list__item--one-column\"') > 1:\n",
    "                                    # (Code for handling positions with promotions)\n",
    "                                else:\n",
    "                                    # (Code for handling positions without promotions)\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                        # Go back if you are inside all experiences\n",
    "                        driver.execute_script(\"window.history.go(-1)\")\n",
    "                        sleep(2)\n",
    "                        soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                        dom = etree.HTML(str(soup2))\n",
    "                        sel = Selector(text=driver.page_source)\n",
    "\n",
    "            # Get education\n",
    "            tree = etree.ElementTree(dom)\n",
    "            find_text = etree.XPath(\"//div[@id='education']\")\n",
    "            for target in find_text(dom):\n",
    "                pos_edu = tree.getpath(target)\n",
    "                list2 = [i for i in pos_edu]\n",
    "                list2[-2] = str(int(pos_edu[-2]) + 2)\n",
    "                if 'navigation-index-see-all-education' in str(soup2):\n",
    "                    list2.append('/div/div/div/a')\n",
    "                    pos_edu = ''.join(list2)\n",
    "                    driver.find_element(\"xpath\", pos_edu).click()\n",
    "                    sleep(2)\n",
    "                    soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    dom = etree.HTML(str(soup2))\n",
    "                    sel = Selector(text=driver.page_source)\n",
    "                    sel_edu = str(soup2)\n",
    "                    num_edu = sel_edu.count('<li class=\"pvs-list__paged-list-item artdeco-list__item \\\n",
    "                                            pvs-list__item--line-separated pvs-list__item--one-column\"')\n",
    "                    i = 0\n",
    "                    education = []\n",
    "                    while i < num_edu:\n",
    "                        i += 1\n",
    "                        tree = etree.ElementTree(dom)\n",
    "                        find_text = etree.XPath(\"//div[@class='application-outlet']\")\n",
    "                        for target in find_text(dom):\n",
    "                            pos_edu = tree.getpath(target)\n",
    "                            listi2 = pos_edu + '/div[3]/div/div/div[2]/div/div/main/section/div[2]/div/div[1]/ul/li[' + str(i) + ']/div/div/div[2]/div[1]/a'\n",
    "                            # (Code for extracting school, degree, and year from education section)\n",
    "                else:\n",
    "                    # (Code for handling education extraction when not going to 'see all education')\n",
    "\n",
    "            writer.writerow([name, title, location, experiences, education, ln_url])\n",
    "            lst.append([name, title, location, experiences, education, ln_url])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred:\", e)\n",
    "            continue\n",
    "\n",
    "    print(lst)\n",
    "    print(profile_urls)\n",
    "    driver.quit()\n",
    "    return render_template('index.html', lst=lst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
