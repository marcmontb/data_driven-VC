{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e14ce4-c76b-4364-ac23-18c8b90cc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code presented in this section is used to take the names of the founders in a spreadsheet cell and\n",
    "#obtain their LinkedIn profiles by using the Python library Requests to perform a search and the package\n",
    "#Beautiful Soup to scrape the results.\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# open excel file and read profiles\n",
    "df = pd.read_excel('list_founders.xlsx')\n",
    "\n",
    "# find linkedin address from profile name and company\n",
    "profile_urls = []  # To store the Profile URLs\n",
    "companies = df.iloc[:, 0].tolist()  # create list of companies\n",
    "founders = df.iloc[:, 2].tolist()  # create list of founders\n",
    "founders = [element for element in founders if str(element) != 'nan']\n",
    "result = []\n",
    "\n",
    "for company, founder in zip(companies, founders):\n",
    "    founder_names = []\n",
    "    if ', and' in founder:\n",
    "        names = founder.split(', and')\n",
    "        for name in names:\n",
    "            name = name.strip()\n",
    "            if ',' in name:\n",
    "                founder_names.extend([n.strip() for n in name.split(',')])\n",
    "            elif 'and' in name:\n",
    "                founder_names.extend([n.strip() for n in name.split('and')])\n",
    "            else:\n",
    "                founder_names.append(name)\n",
    "    else:\n",
    "        founder_names = [name.strip() for name in re.split(r',\\s| and ', founder)]\n",
    "    result.append([company] + founder_names)\n",
    "\n",
    "for i in result:\n",
    "    company = i[0]\n",
    "    names = pd.Series(i[1:])\n",
    "    names = names[~pd.isna(names)].values.tolist()\n",
    "    for name in names:\n",
    "        profile = []\n",
    "        text = 'site:linkedin.com/in/ AND \"{}\" AND \"{}\" '.format(company, name)\n",
    "        query = 'https://google.com/search?q=' + text\n",
    "        cookies = {\"CONSENT\": \"YES+shp.gws-20210330-0-RC1.de+FX+412\"}\n",
    "        response = requests.get(query, cookies=cookies)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for anchor in soup.find_all('a'):\n",
    "            url = anchor[\"href\"]\n",
    "            if 'https://www.linkedin.com/' in url:\n",
    "                url = url[7:url.find('&')]\n",
    "                profile.append(url)\n",
    "        try:\n",
    "            profile_urls.append(profile[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(profile_urls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
